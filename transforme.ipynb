{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bccfd994-2a67-4355-ada8-75324206f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f24ad8-6af9-41f5-b57e-6eeb16b449e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "text = open(\"input.txt\").read()\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b1352a-0aef-4462-8e3f-0b8531cc81ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz 65\n",
      "weodassf [61, 43, 53, 42, 39, 57, 57, 44]\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "itos = {i:s for i,s in enumerate(chars)}\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "vocab_size = len(chars)\n",
    "print(vocab_size)\n",
    "print(\"\".join(chars), vocab_size)\n",
    "\n",
    "encode = lambda s : [stoi[c] for c in s]\n",
    "decode = lambda s : \"\".join([itos[c] for c in s])\n",
    "mess = \"weodassf\"\n",
    "print(decode(encode(\"weodassf\")),encode(\"weodassf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c03d118-dd3b-4281-920d-2097ac8a2475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59]\n",
      "1003854\n"
     ]
    }
   ],
   "source": [
    "data = encode(text)\n",
    "print(data[:100])\n",
    "\n",
    "n = int(len(data) * 0.9)\n",
    "print(n)\n",
    "train_data = data[:n]\n",
    "var_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfc192af-f83a-4f9a-8991-b7aaa0accf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111540\n"
     ]
    }
   ],
   "source": [
    "print(len(var_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "504c7f31-1225-44ad-b926-134a98ec0d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "block_size = 256  # 最长上下文长度\n",
    "batch_size = 64\n",
    "vocab_size = len(chars)\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faffca25-d049-4c83-9004-afd7f82230a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1, 45, 53,  ..., 47, 58, 46],\n",
       "         [20, 10,  0,  ..., 30, 31, 10],\n",
       "         [58,  1, 57,  ..., 39, 61,  1],\n",
       "         ...,\n",
       "         [39, 51, 43,  ..., 53, 59,  1],\n",
       "         [46, 47, 51,  ...,  1, 46, 43],\n",
       "         [39, 47, 52,  ...,  1, 46, 39]], device='cuda:0'),\n",
       " tensor([[45, 53,  8,  ..., 58, 46,  1],\n",
       "         [10,  0, 13,  ..., 31, 10,  0],\n",
       "         [ 1, 57, 43,  ..., 61,  1, 58],\n",
       "         ...,\n",
       "         [51, 43,  1,  ..., 59,  1, 41],\n",
       "         [47, 51,  8,  ..., 46, 43, 39],\n",
       "         [47, 52, 57,  ..., 46, 39, 58]], device='cuda:0'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else var_data\n",
    "    ix = torch.randint(0,len(data) - block_size, (batch_size,))\n",
    "    x = [data[i:i + block_size] for i in ix]\n",
    "    y = [data[i+1:i + block_size + 1] for i in ix]\n",
    "    x = torch.tensor(x).to(device)\n",
    "    y = torch.tensor(y).to(device)\n",
    "    return x,y\n",
    "    \n",
    "get_batch(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90e8b3ef-532e-4256-b376-61f1b7eeb639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256]) torch.Size([16384, 65]) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.head_size_sqrt = head_size**-0.5\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        v = self.value(x)\n",
    "        weight = k @ q.transpose(-2,-1) * self.head_size_sqrt\n",
    "        weight = weight.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n",
    "        weight = weight.softmax(-1)\n",
    "        weight = self.dropout(weight)\n",
    "        out = weight @ v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_head, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_head)])\n",
    "        self.proj = nn.Linear(num_head*head_size, num_head*head_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, fan_in, fan_out):\n",
    "        super().__init__()\n",
    "        self.nn = nn.Sequential(\n",
    "            nn.Linear(fan_in, 4 * fan_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * fan_out, fan_out),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.nn(x)\n",
    "        return out\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa_heads = MultiHeadAttention(n_head, head_size)\n",
    "        self.fforward = FeedForward(n_embd,n_embd)\n",
    "        self.layer_nom1 = nn.LayerNorm(n_embd)\n",
    "        self.layer_nom2 = nn.LayerNorm(n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.sa_heads(self.layer_nom1(x))\n",
    "        out = x + self.fforward(self.layer_nom2(x))\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[Block(n_embd, n_head) for _ in range(n_layer)]\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)   # B,T,C  4 * 8 * 65  batch, block, n_embed\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))  # T * C\n",
    "        x_emb = tok_emb + pos_emb\n",
    "        x = self.blocks(x_emb)\n",
    "        x = self.layer_norm(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)  # logits的第二个维度为通道数 C\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_generate_tokens):\n",
    "        for _ in range(max_generate_tokens):\n",
    "            idx_use = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_use)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=-1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel().to(device)\n",
    "\n",
    "ix,targets = get_batch(\"train\")\n",
    "logits, loss = model(ix, targets)\n",
    "print(ix.shape,logits.shape,  loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8f12690-43a2-4aa5-ac73-b75efefcdd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# print(model.sa_heads.heads[0].key.weight.device)\n",
    "print(model.token_embedding_table.weight.device)\n",
    "print(model.sa_heads.key.weight.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5d23fe2-13e8-43d0-8db3-ad5a21dd3d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': tensor(4.3095), 'val': tensor(4.3146)}\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        loss_s = torch.zeros(eval_iter)\n",
    "        for k in range(eval_iter):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            loss_s[k] = loss\n",
    "        out[split] = loss_s.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "eval_iter = 50\n",
    "losses = estimate_loss()\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b5875df-4658-4395-a688-45c1325241af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter = 0\n",
    "iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "827ec242-e4bc-459e-931a-85b91eaeeb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200 {'train': tensor(2.6248), 'val': tensor(2.6178)}\n",
      "2300 {'train': tensor(2.6189), 'val': tensor(2.6126)}\n",
      "2400 {'train': tensor(2.6198), 'val': tensor(2.6147)}\n",
      "2500 {'train': tensor(2.6180), 'val': tensor(2.6129)}\n",
      "2600 {'train': tensor(2.6184), 'val': tensor(2.6106)}\n",
      "2700 {'train': tensor(2.6201), 'val': tensor(2.6095)}\n",
      "2800 {'train': tensor(2.6172), 'val': tensor(2.6113)}\n",
      "2900 {'train': tensor(2.6174), 'val': tensor(2.6079)}\n",
      "3000 {'train': tensor(2.6199), 'val': tensor(2.6105)}\n",
      "3100 {'train': tensor(2.6189), 'val': tensor(2.6111)}\n",
      "3200 {'train': tensor(2.6145), 'val': tensor(2.6085)}\n",
      "3300 {'train': tensor(2.6127), 'val': tensor(2.6077)}\n",
      "3400 {'train': tensor(2.6142), 'val': tensor(2.6074)}\n",
      "3500 {'train': tensor(2.6163), 'val': tensor(2.6059)}\n",
      "3600 {'train': tensor(2.6131), 'val': tensor(2.6044)}\n",
      "3700 {'train': tensor(2.6136), 'val': tensor(2.6072)}\n",
      "3800 {'train': tensor(2.6179), 'val': tensor(2.6067)}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28miter\u001b[39m, losses)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 12\u001b[0m xb, yb \u001b[38;5;241m=\u001b[39m \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m model(xb, yb)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# print(iter, loss.item())\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m, in \u001b[0;36mget_batch\u001b[1;34m(split)\u001b[0m\n\u001b[0;32m      4\u001b[0m x \u001b[38;5;241m=\u001b[39m [data[i:i \u001b[38;5;241m+\u001b[39m block_size] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ix]\n\u001b[0;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m [data[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:i \u001b[38;5;241m+\u001b[39m block_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ix]\n\u001b[1;32m----> 6\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x,y\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "batch_size = 64\n",
    "eval_iter = 100\n",
    "max_iter = 10001\n",
    "eval_intval = 100\n",
    "for _ in range(max_iter):\n",
    "    if iter % eval_intval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(iter, losses)\n",
    "    iter += 1\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    logits, loss = model(xb, yb)\n",
    "    # print(iter, loss.item())\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5f9bab6-5949-488e-bd1f-e5626734dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "增加感知层前\n",
    "10000 {'train': tensor(2.4731), 'val': tensor(2.4791)}\n",
    "增加自模块后注意力\n",
    "10000 {'train': tensor(2.3335), 'val': tensor(2.3796)}\n",
    "增加多头注意力模块后\n",
    "10000 {'train': tensor(2.1353), 'val': tensor(2.2121)}\n",
    "增加feedforward层后\n",
    "10000 {'train': tensor(2.1136), 'val': tensor(2.1898)}\n",
    "上下文长度增加到 8 -> 128\n",
    "10000 {'train': tensor(2.0526), 'val': tensor(2.1474)}   还是在胡言乱语\n",
    "上下文长度改为32,将MuiltHeadAttention模块和FeedForward模块整合为Block模块,并重复三次\n",
    "10000 {'train': tensor(2.0836), 'val': tensor(2.1342)}   从loss变化来看，还可以优化，目前效果一般，输出的词句比之前的更好\n",
    "20000 {'train': tensor(1.9490), 'val': tensor(2.0583)}   loss仍有变小的空间\n",
    "在每个block和下一个block之间使用残差，在MulitHead和FeedForward之间也使用残差，并在两层中各加入一个映射层，FeedForward内的映射空间*4\n",
    "10000 {'train': tensor(1.6888), 'val': tensor(1.8706)}   词不成词，有点像了\n",
    "增加 layerNorm (在网络很深的情况下解决梯度消失的问题)\n",
    "10000 {'train': tensor(1.7071), 'val': tensor(1.8853)}\n",
    "\n",
    "在每一层增加dropout,调整参数如下:\n",
    "block_size = 256  # 最长上下文长度\n",
    "batch_size = 64\n",
    "vocab_size = len(chars)\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6dbbfbd9-4550-4aee-80ee-4d7b0148c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='transforme_model.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05501101-ef29-4b16-b896-316ccf8aacab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "61bcbde5-7477-452b-8d6f-34b649fe4b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtok tensor([[[-0.5852, -2.5080, -0.6448,  0.2537, -0.8769, -0.6065,  1.6361,\n",
      "          -0.2576,  0.2752,  0.4963,  0.3526,  1.9479,  0.7058,  0.3186,\n",
      "           1.0628,  1.3333, -0.2504,  2.3920,  1.2918, -0.6879,  0.1844,\n",
      "           1.1304,  0.8146,  0.1405, -0.0558, -0.0974, -0.2782, -0.2414,\n",
      "          -0.0753, -0.5407,  0.7578,  1.1906],\n",
      "         [ 0.1850,  1.0776,  1.3447,  0.7234, -1.0138, -1.0299, -0.9673,\n",
      "           0.3816,  0.2881, -0.9173, -1.4991, -0.0268, -0.9305, -0.1229,\n",
      "           0.9787,  1.2514,  1.6764, -1.9643,  0.3712, -1.3294, -0.5953,\n",
      "          -2.8730, -0.2136,  1.3524,  0.2069,  1.8155, -0.6207,  1.7972,\n",
      "           0.9435, -1.2690,  0.7967, -0.8893],\n",
      "         [-0.3401,  0.2677,  1.6034,  1.1019, -1.1222,  0.7689,  0.2933,\n",
      "          -1.0155,  1.4306, -0.2832,  1.0406, -0.5213, -0.7524, -0.5851,\n",
      "          -0.1625, -0.1326, -0.2874,  0.8236,  0.3090,  0.6382, -0.1096,\n",
      "           0.7588,  0.5967, -1.2729, -2.2114,  1.2830, -0.6859, -0.4435,\n",
      "          -0.6575, -0.5347,  1.1580, -1.8221]]], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([1, 3, 32])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[0,1,2]]).to(device)\n",
    "xtok = model.token_embedding_table(x)\n",
    "print(\"xtok\", xtok)\n",
    "xpos = model.position_embedding_table(x)\n",
    "print(xpos.shape)\n",
    "x_emb = xtok + xpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0b0cd4d5-4634-42c8-8ec3-679cee8c4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, C = x_emb.shape\n",
    "head_size = 2\n",
    "key = nn.Linear(C,head_size, bias=False, device=device)\n",
    "query = nn.Linear(C,head_size, bias=False, device=device)\n",
    "value = nn.Linear(C, head_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "585f4a0a-cb03-4d28-89c8-3d31b8c2f583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3254,  0.1134],\n",
      "         [-1.1443, -0.6934],\n",
      "         [ 1.4930, -0.3336]]], device='cuda:0', grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[-0.3669, -0.6379],\n",
      "         [-1.4149, -0.0669],\n",
      "         [-0.9649, -0.1618]]], device='cuda:0', grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 3, 2]) torch.Size([1, 3, 2])\n",
      "tensor([[[ 0.0332,  0.6096, -0.2368],\n",
      "         [ 0.3202,  1.1777, -1.4779],\n",
      "         [ 0.2090,  0.8601, -0.9805]]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]], device='cuda:0')\n",
      "tensor([[[ 0.0332,    -inf,    -inf],\n",
      "         [ 0.3202,  1.1777,    -inf],\n",
      "         [ 0.2090,  0.8601, -0.9805]]], device='cuda:0',\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "tensor([[[1.0000, 0.0000, 0.0000],\n",
      "         [0.2979, 0.7021, 0.0000],\n",
      "         [0.3104, 0.5952, 0.0945]]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[[-0.1688, -0.2627],\n",
      "         [-1.0833, -0.4400],\n",
      "         [ 0.3279,  0.2186]]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "k = key(x_emb)  # (B,T,C) @ (C, H) -> (B,T,H)\n",
    "print(k)\n",
    "q = query(x_emb)  # (B,T,C) @ (C, H) -> (B,T,H)\n",
    "print(q)\n",
    "print(k.shape, q.shape)\n",
    "weight = q @ k.transpose(-1,-2) * head_size**-0.5  # (B,T,H) @ (B,H,T) -> (B,T,T)\n",
    "print(weight)\n",
    "tril = torch.tril(torch.ones(T,T)).to(device)\n",
    "print(tril)\n",
    "weight = weight.masked_fill(tril == 0, float('-inf'))\n",
    "print(weight)\n",
    "weight = F.softmax(weight, 2)  # (B,T,T) -> (B,T,T_mean)\n",
    "print(weight)\n",
    "v = value(x_emb)   # (B,T,C) @ (C, H) -> (B,T,H)\n",
    "print(v)\n",
    "out = weight @ v   # (B,T,T_mean) @ (B,T,H) -> (B,T,H)\n",
    "print(out.shape)  # B * T * H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a59a75d-c6af-459b-b4f7-a61f340a44bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
